{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6049e15aeabf11f",
   "metadata": {},
   "source": [
    "# Code for Adding Latitude and Longitude and Mapping Reprints\n",
    "\n",
    "The following notebook enriches lynch_clusters with longitude and latitude data for the cities of their reports. I also put together interactive maps for the clusters. These maps show location of reprints, the newspaper and its city, the victim name, and the clippings.\n",
    "\n",
    "Steps in this notebook:\n",
    "1) Review Viral Texts' place metadata.\n",
    "2) Get sn codes for lynch_clusters (extracted from 'URL' column)\n",
    "3) Match sn codes with instances in 'series.csv' then extract 'coverage' data\n",
    "4) Match coverage with instances in 'places.csv' then extract latitudinal and longitudanl data\n",
    "5) Map the data with folium.\n",
    "6) Display the data based on user selection using ipywidgets."
   ]
  },
  {
   "cell_type": "code",
   "id": "c46a199560de85a5",
   "metadata": {},
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import os\n",
    "import folium\n",
    "from folium.plugins import MarkerCluster\n",
    "import webbrowser\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "1) review Viral Texts' place metadata:",
   "id": "1e0f46e778a912ed"
  },
  {
   "cell_type": "code",
   "id": "d86f1cbab81bfa8a",
   "metadata": {},
   "source": [
    "lat_long_df = pd.read_csv('https://raw.githubusercontent.com/ViralTexts/newspaper-metadata/main/places.csv')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c7df40281c82eb04",
   "metadata": {},
   "source": [
    "series_df = pd.read_csv('https://raw.githubusercontent.com/ViralTexts/newspaper-metadata/main/series.csv')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1d731bd1bf2de5bf",
   "metadata": {},
   "source": [
    "lat_long_df.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "bb74dd625febe6fa",
   "metadata": {},
   "source": [
    "series_df.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "2) Get sn codes for lynch_clusters (extracted from 'URL' column):",
   "id": "64c505f28d4b6b62"
  },
  {
   "cell_type": "code",
   "id": "c8e1e3932742a3fe",
   "metadata": {},
   "source": [
    "# extract sn codes from URL column\n",
    "\n",
    "directory = '/Users/matthewkollmer/PycharmProjects/nlp_research/vrt_work/lynch_clusters'\n",
    "\n",
    "sn_code_regex = re.compile(r'sn\\d{8}')\n",
    "\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith('.csv'):\n",
    "        file_path = os.path.join(directory, filename)\n",
    "        \n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        sn_codes = []\n",
    "        \n",
    "        for url in df['URL']:\n",
    "            if pd.isna(url):\n",
    "                sn_codes.append(None)\n",
    "                \n",
    "            else:\n",
    "                sn_match = sn_code_regex.search(url)\n",
    "                \n",
    "                if sn_match:\n",
    "                    sn_codes.append(sn_match.group(0))\n",
    "                    \n",
    "                else:\n",
    "                    sn_codes.append(None)\n",
    "        \n",
    "        df['sn_code'] = sn_codes\n",
    "        \n",
    "        df['sn_code'] = '/lccn/' + df['sn_code']\n",
    "        \n",
    "        df.to_csv(file_path, index=False)\n",
    "        print(f'Updated {filename} with clippings.')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "3) Match sn codes with instances in 'series.csv' then extract 'coverage' data:",
   "id": "acb14d2886fb57fd"
  },
  {
   "cell_type": "code",
   "id": "94a85b7fdf9d26da",
   "metadata": {},
   "source": [
    "# match sn codes between 'series' dataframe and victim csv files\n",
    "\n",
    "directory = '/Users/matthewkollmer/PycharmProjects/nlp_research/vrt_work/lynch_clusters'\n",
    "\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith('.csv'):\n",
    "        file_path = os.path.join(directory, filename)\n",
    "        \n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        df['coverage'] = None\n",
    "        \n",
    "        for i, sn_code in series_df['series'].items():\n",
    "\n",
    "            matching_sn_codes = df['sn_code'] == sn_code\n",
    "            \n",
    "            df.loc[matching_sn_codes, 'coverage'] = series_df.loc[i, 'coverage']\n",
    "        \n",
    "        df.to_csv(file_path, index=False)\n",
    "        print(f'Updated {filename} with coverage links.')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "4) Match coverage with instances in 'places.csv' then extract latitudinal and longitudanl data:",
   "id": "a62d8497bca6f2ce"
  },
  {
   "cell_type": "code",
   "id": "5baa65ad422995a7",
   "metadata": {},
   "source": [
    "# match 'coverage' column in victim csv files to 'coverage' column in 'places.csv'/lat_long_df and transfer lat/long data to victim csv files\n",
    "\n",
    "directory = '/Users/matthewkollmer/PycharmProjects/nlp_research/vrt_work/lynch_clusters'\n",
    "\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith('.csv'):\n",
    "        file_path = os.path.join(directory, filename)\n",
    "        \n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        df['longitude'] = None\n",
    "        df['latitude'] = None\n",
    "        \n",
    "        for i, coverage_link in lat_long_df['coverage'].items():\n",
    "   \n",
    "            matching_rows = df['coverage'] == coverage_link\n",
    "\n",
    "            df.loc[matching_rows, 'longitude'] = lat_long_df.loc[i, 'lon']\n",
    "            df.loc[matching_rows, 'latitude'] = lat_long_df.loc[i, 'lat']\n",
    "        \n",
    "        df.to_csv(file_path, index=False)\n",
    "        print(f'Updated {filename} with longitude and latitude data.')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "5) Map the data with folium.\n",
    "\n",
    "I spent way too much time on this. But it works! And it's customized so the cluster icons are dark red."
   ],
   "id": "2c2afe0079eead43"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "directory = '/Users/matthewkollmer/PycharmProjects/nlp_research/vrt_work/lynch_clusters/'\n",
    "output_directory = '/Users/matthewkollmer/PycharmProjects/nlp_research/vrt_work/lynch_cluster_maps/'\n",
    "\n",
    "def build_maps(file_path):\n",
    "    file_name = os.path.basename(file_path)\n",
    "    victim_name = file_name.replace('.csv', '').replace('_', ' ')\n",
    "    \n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    df = df.dropna(subset=['latitude', 'longitude'])\n",
    "    \n",
    "    map_center = [39.8283, -98.5795]  # this is roughly the central location of the USA. Googled it.\n",
    "    \n",
    "    folium_map = folium.Map(location=map_center, zoom_start=3, tiles=\"CartoDB positron\")\n",
    "\n",
    "    # I don't actually know javascript. Thanks ChatGPT!\n",
    "    marker_cluster = MarkerCluster(\n",
    "        icon_create_function=\"\"\"\n",
    "        function (cluster) {\n",
    "            var count = cluster.getChildCount();\n",
    "            var size = 'small';\n",
    "            var iconSize = L.point(1, 1);\n",
    "            \n",
    "            var color = 'rgba(139, 0, 0,';\n",
    "            \n",
    "            if (count < 4) {\n",
    "                color += '.4)';\n",
    "            } else if (count < 10) {\n",
    "                color += '.6)';\n",
    "            } else {\n",
    "                color += '1)'; \n",
    "            }\n",
    "            \n",
    "            return L.divIcon({\n",
    "                html: '<div style=\"background-color:' + color + '; color:white;\"><span style=\"color:white;\">' + count + '</span></div>',\n",
    "                className: 'marker-cluster marker-cluster-' + size,\n",
    "                iconSize: iconSize\n",
    "            });\n",
    "        }\n",
    "        \"\"\"\n",
    "    ).add_to(folium_map)\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        latitude = row['latitude']\n",
    "        longitude = row['longitude']\n",
    "        link_title = row['Link Title']\n",
    "        clipping = row['clippings']\n",
    "        \n",
    "        popup_text = f\"Victim: {victim_name}<br><br>Newspaper: {link_title}<br><br>Newspaper Clipping: <br> {clipping}\"\n",
    "        \n",
    "        folium.CircleMarker(\n",
    "            location=[latitude, longitude],\n",
    "            radius=4,\n",
    "            color='darkred',\n",
    "            popup=folium.Popup(popup_text, max_width=300)\n",
    "        ).add_to(marker_cluster)\n",
    "    \n",
    "    output_html = os.path.join(output_directory, file_name.replace('.csv', '.html'))\n",
    "    folium_map.save(output_html)\n",
    "    print(f'{victim_name} map saved to {output_html}')\n",
    "\n",
    "files = [f for f in os.listdir(directory) if f.endswith('.csv')]\n",
    "\n",
    "for file_name in files:\n",
    "    file_path = os.path.join(directory, file_name)\n",
    "    build_maps(file_path)"
   ],
   "id": "1d48c2c1c1c03fa3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "6) Display the data based on user selection using ipywidgets.",
   "id": "9527082f79462fa"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "map_directory = '/Users/matthewkollmer/PycharmProjects/nlp_research/vrt_work/lynch_cluster_maps/'\n",
    "\n",
    "def open_map_in_browser(file_name):\n",
    "    file_path = os.path.join(map_directory, file_name)\n",
    "    webbrowser.open(f'file://{file_path}')\n",
    "\n",
    "list_of_maps = [f for f in os.listdir(map_directory) if f.endswith('.html')]\n",
    "\n",
    "dropdown = widgets.Dropdown(\n",
    "    options=list_of_maps,\n",
    "    description='Select Map:',\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "def open_sesame(change):\n",
    "    open_map_in_browser(change['new'])\n",
    "\n",
    "dropdown.observe(open_sesame, names='value')\n",
    "\n",
    "display(dropdown)"
   ],
   "id": "ac2c80ab17c1b2e7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "9e7ccbd32d651c03",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
